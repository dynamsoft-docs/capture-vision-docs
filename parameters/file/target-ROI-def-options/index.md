---   
layout: default-layout
title:  TargetROIDef Object Introduction
description: Introduced the TargetROIDef definition for Dynamsoft Capture Vision.
keywords: TargetROIDef
needAutoGenerateSidebar: true
noTitleIndex: true
---

# Design of the TargetROIDef Object

The `TargetROIDef` object is used to specify one or more recognition tasks to be performed on some regions of interest (ROIs) within an image.

```json
{
    "Name" : "TA_1",
    "TaskSettingNameArray": [
        "LR_0",// Name of LabelRecognizerTaskSetting Object
        "BR_0",// Name of BarcodeReaderTaskSetting Object
        "DN_0" // Name of DocumentNormalizerTaskSetting Object
    ], 
    "Location": 
    {
        "ReferenceObjectFilter":
        {  
            //...
        },
        "Offset": 
        {  
            //...
        }
    },
    "PauseFlag": 0,
    "BaseTargetROIDefName" : ""
}
```

<div align="center">
   <p>Example 1 – Parameters of TargetROIDef</p>
</div>

As shown in the example above, the parameters in this object are as follows:

| Parameter Name | Description |
| -------------- | ----------- |
| `Name` | Represents the name of the `TargetROIDef` object, which serves as its unique identifier. |
| `TaskSettingNameArray` | Represents the collection of task setting object names, used to refer to the `BarcodeReaderTaskSetting`,`LabelRecognizerTaskSetting`,`DocumentNormalizerTaskSetting` objects. It is used to define recognition tasks such as reading barcodes, recognizing labels, or detecting document quads. |
| `Location` | Define the spatial location where the recognition tasks are performed. It consists of a `ReferenceObjectFilter` object and a `Offset` object. |
| `PauseFlag`| Indicates that the region results generated by this `TargetROIDef` will not be used by other `TargetROIDef` objects that depend on it to calculate the target regions, unless the user explicitly performs an Update operation.|
| `BaseTargetROIDefName` | Represents the name of another `TargetROIDef` object. It is used to inherit the parameters defined in its parent TargetROIDef object. |

<div align="center">
   <p>Table 1 – Parameters Summary of TargetROIDef</p>
</div>

In simple terms, `TargetROIDef` can be expressed using the following formula:

```json
TargetROIDef = Recognition Task Definition + Spatial Location Definition
```

## Recognition Tasks

The recognition tasks configured on the `TargetROIDef` object include barcode recognition, label recognition, document boundary detection, etc. 
The atomic result of each task type is the smallest output item, which can be a barcode, text line, table cell, detected quadrilateral, etc. `CapturedResult` represents a set of all captured atomic result items on an image. The following table lists the task types and corresponding atomic result item types.

| Task Type                 | Performed By | Atomic Result Type     |
| :-------------------      | :----------- | :------------------- |
| Read Barcodes             | Dynamsoft Barcode Reader SDK          | BarcodeResultItem               |
| Recognize Text Lines      | Dynamsoft Label Recognizer SDK        | TextResultItem                  |
| Detect Document Borders   | Dynamsoft Document Normalizer SDK     | DetectedQuadResultItem          |
| Normalize a Document      | Dynamsoft Document Normalizer SDK     | NormalizedImageResultItem       |

If you want to learn more about the design details of barcode reader task settings, please refer to this link.
If you want to learn more about the design details of label recognizer task settings, please refer to this link.
If you want to learn more about the design details of document normalizer task settings, please refer to this link.

## Spatial Location

Parameter `Location` defines the spatial location where the recognition tasks are performed. It consists of a `ReferenceObjectFilter` parameter and a `Offset` parameter. The former is used to filter out the desired reference regions, and the latter defines a uniform offset relative to the reference regions.
Next, we focus on explaining some key concepts based on the example diagram below:

<div align="center">
   <p><img src="../assets/roi-concept.png" alt="An example showing the key concepts" width="100%" /></p>
   <p>Figure 2 – An example showing the key concepts</p>
</div>

|Concept|Description|Explanation with example|
|:------|:----------|:-----------------------|
|**Atomic Result**| Represents the atomic result of the recognition task output. It can be a color detection region, a barcode, a text line, a table cell, a detected quadrilateral etc.|`T1`, `T2`, `T3` are three atomic result objects of `TextLineResultItem` type, and B1 is one atomic object of `BarcodeResultItem` type.|
|**Reference Region**|A reference region is a physical quadrilateral region. It includes two types: **entire image region** and **atomic result region**. The former refers to the quadrilateral extent of the original image, and the latter refers to the quadrilateral extent of each atomic result.| `ROI1` has only one reference region which is the entire image region. `ROI2` has three reference regions which generated from `T1`, `T2`, `T3`. |
|**Target Region**| A target region is a physical quadrilateral region, which is calculated from a reference region and offset.| `ROI1` has only one target region, which is equal to the reference region. `ROI2` has three target regions, which are calculated by offsets from quadrilateral regions of `T1`, `T2`, `T3`.|

### Reference Object Filter

```json
{
    //...
    "Location": 
    {
        "ReferenceObjectFilter" :
        {  
            "ReferenceTargetROIDefNameArray": ["TR_0"], 
            "AtomicResultTypeArray" : ["ART_BARCODE"], 
            "BarcodeFilteringCondition": {},
            "FrameFilteringCondition": {},
            "TextLineFilteringCondition": {},
            "ColourRegionFilteringCondition": {}
        },
        "Offset" :
        {
            //...
        }
    },
    //...
}
```

### Offset

```json
{
    //...
    "Location": 
    {
        "ReferenceObjectFilter" :
        {  
            //...
        },
        "Offset" :
        {
            "ReferenceObjectOriginIndex": 0,
            "ReferenceObjectSizeType": "default",
            "MeasuredInPercentage" : 1,
            "FirstPoint" : [ 0, 0 ],
            "SecondPoint" : [ 100, 0 ],
            "ThirdPoint" : [ 100, 100 ],
            "FourthPoint" : [ 0, 100 ]
        }
    },
}
```
